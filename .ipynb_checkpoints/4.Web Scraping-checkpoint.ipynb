{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of data aren't accessible through data sets or APIs. They may exist on the Internet as Web pages, though. One way to access the data without waiting for the provider to create an API is to use a technique called Web scraping.\n",
    "\n",
    "Web scraping allows us to load a Web page into Python and extract the information we want. We can then work with the data using standard analysis tools like pandas and numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can do Web scraping, we need to understand the structure of the Web page we're working with, then find a way to extract parts of that structure in a sensible way.\n",
    "\n",
    "We'll use the requests library heavily as we learn about Web scraping. This library enables us to download a Web page. We'll also use the beautifulsoup library to extract the relevant parts of the Web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web pages use HyperText Markup Language (HTML). HTML isn't a programming language like Python. It's a markup language with its own syntax and rules. When a Web browser like Chrome or Firefox downloads a Web page, it reads the HTML to determine how to render it and display it to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML consists of tags. Anything in between the opening and closing of a tag is the content of that tag. We can nest tags to create complex formatting rules.\n",
    "\n",
    "HTML documents contain a few major sections. The head section contains information that's useful to the Web browser that's rendering the page; the user doesn't see it. The body section contains the bulk of the content the user interacts with on the page.\n",
    "\n",
    "Different tags have different purposes. For example, the title tag tells the Web browser what page title to display at the top of our tab. The p tag indicates that the content inside it is a single paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we'll make a GET request to http://dataquestio.github.io/web-scraping-pages/simple.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = response.content\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the page is the easy part. Let's say that we want to get the text in the first paragraph. Now we need to parse the page and extract the information we want.\n",
    "\n",
    "We'll use the BeautifulSoup library to parse the Web page with Python. This library allows us to extract tags from an HTML document.\n",
    "\n",
    "We can think of HTML documents as \"trees,\" and the nested tags as \"branches\" (similar to a family tree). BeautifulSoup works the same way.\n",
    "\n",
    "If we look at [this page](http://dataquestio.github.io/web-scraping-pages/simple.html), for example, the root of the \"tree\" is the html tag.\n",
    "\n",
    "The html tag contains two \"branches,\" head and body. head contains one \"branch,\" title. body contains one branch, p. Drilling down through these multiple branches is one way to parse a Web page.\n",
    "\n",
    "To extract the text inside the p tag, we would first need to get the body element, then the p element, and then finally the text inside the p element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the text inside the title tag\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Initialize the parser, and pass in the content variable\n",
    "\n",
    "parser =  BeautifulSoup(content , \"html.parser\")\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the body tag from the document.\n",
    "# Since we passed in the top level of the document to the parser, \n",
    "# we need to pick a branch off of the root.\n",
    "# With BeautifulSoup, we can access branches by using tag types as attributes\n",
    "\n",
    "body = parser.body\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get the p tag from the body.\n",
    "p = body.p\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's nice to use the tag type as a property, it's not always a very robust way to parse a document. It's usually better to be more explicit by using the find_all method. This method will find all occurrences of a tag in the current element, and return a list.\n",
    "\n",
    "If we only want the first occurrence of an item, we'll need to index the list to get it. Aside from this difference, it behaves the same way as passing in the tag type as an attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "body = parser.find_all(\"body\")\n",
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = body[0].find_all(\"p\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A simple example page'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = parser.find_all(\"title\")\n",
    "title[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML allows elements to have IDs. Because they are unique, we can use an ID to refer to a specific element.\n",
    "\n",
    "HTML uses the div tag to create a divider that splits the page into logical units. We can think of a divider as a \"box\" that contains content. For example, different dividers hold a Web page's footer, sidebar, and horizontal menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p id=\"second\">\n",
       "<b>\n",
       "                Second paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the page content and set up a new parser.\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple_ids.html\")\n",
    "\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"first\">\n",
      "                First paragraph.\n",
      "            </p>\n"
     ]
    }
   ],
   "source": [
    "print(parser.find_all(\"p\", id=\"first\" )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                Second paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parser.find_all(\"p\",id=\"second\")[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In HTML, elements can also have classes. Classes aren't globally unique. In other words, many different elements belong to the same class, usually because they share a common purpose or characteristic.\n",
    "\n",
    "For example, we may want to create three dividers to display three of your photographs. we can create a common look and feel for these dividers, such as a border and caption style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where classes come into play. We could create a class called \"gallery,\" define a style for it once using CSS, and then apply that class to all of the dividers we'll use to display photos. One element can even have multiple classes.\n",
    "\n",
    "We can use find_all to select elements by class. We'll just need to pass in the class_ parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <div>\\n            <p class=\"inner-text\">\\n                First paragraph.\\n            </p>\\n            <p class=\"inner-text\">\\n                Second paragraph.\\n            </p>\\n        </div>\\n        <p class=\"outer-text\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>\\n        <p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the website that contains classes ---http://dataquestio.github.io/web-scraping-pages/simple_classes.html.\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple_classes.html\")\n",
    "content = response.content\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                First paragraph.\n",
      "            \n",
      "\n",
      "                Second paragraph.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "parser  = BeautifulSoup(content, \"html.parser\")\n",
    "print(parser.find_all(\"p\", class_=\"inner-text\")[0].text)\n",
    "print(parser.find_all(\"p\", class_=\"inner-text\")[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n",
      "\n",
      "\n",
      "                Second outer paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parser.find_all(\"p\", class_ = \"outer-text\")[0].text)\n",
    "print(parser.find_all(\"p\", class_ = \"outer-text\")[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cascading Style Sheets, or CSS, is a language for adding styles to HTML pages. We can use selectors to add background colors, text colors, borders, padding, and many other style choices to the elements on HTML pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CSS will make all of the text inside all paragraphs red:\n",
    "\n",
    "p{\n",
    "    color: red\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CSS will change the text color to red for any paragraphs that have the class inner-text. We select classes with the period or dot symbol (.):\n",
    "\n",
    "p.inner-text{\n",
    "    color: red\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CSS will change the text color to red for any paragraphs that have the ID first. We select IDs with the pound or hash symbol (#):\n",
    "\n",
    "p#first{\n",
    "    color: red\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also style IDs and classes without using any specific tags. For example, this CSS will make the element with the ID first red (not just paragraphs):\n",
    "\n",
    "#first{\n",
    "    color: red\n",
    " }\n",
    " \n",
    "This CSS will make any element with the class inner-text red:\n",
    "\n",
    ".inner-text{\n",
    "    color: red\n",
    " }\n",
    " \n",
    "In the examples above, we used CSS selectors to select one or more elements, then apply styles to only those elements. CSS selectors are very powerful and flexible.\n",
    "\n",
    "Perhaps not surprisingly, we also use CSS selectors to select elements when we do Web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use BeautifulSoup's .select method to work with CSS selectors. \n",
    "\n",
    "Here's the HTML we'll be working with http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the website that contains classes and IDs.\n",
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all of the elements that have the class outer-text.\n",
    "print(parser.select(\".outer-text\")[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                First outer paragraph.\n",
      "            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all of the elements that have the ID second\n",
    "print(parser.select(\"#second\")[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can nest CSS selectors similar to the way HTML nests tags. For example, we could use selectors to find all of the paragraphs inside the body tag. Nesting is a very powerful technique that enables us to use CSS to do complex Web scraping tasks.\n",
    "\n",
    "This selector will target any paragraph inside a div tag:\n",
    "\n",
    "div p\n",
    "\n",
    "This selector will target any item inside a div tag that has the class first-item:\n",
    "\n",
    "div .first-item\n",
    "\n",
    "This one is even more specific. It selects any item that's inside a div tag inside a body tag, but only if it also has the ID first:\n",
    "\n",
    "body div #first\n",
    "\n",
    "This selector zeroes in on any items with the ID first that are inside any items with the class first-item:\n",
    "\n",
    ".first-item #first\n",
    "\n",
    "As we can see, we can nest CSS selectors in infinite ways. This allows us to extract data from websites with complex layouts. We can test selectors by using the .select method as we write them. Because it's easy to write a selector that doesn't work the way we expect. We can use them with the same .select method we used for our CSS selectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"http://dataquestio.github.io/web-scraping-pages/2014_super_bowl.html\")\n",
    "content = response.content\n",
    "parser = BeautifulSoup(content, \"html.parser\")\n",
    "\n",
    "# Total Plays for the New England Patriots\n",
    "print(parser.select(\"#total-plays\")[0].select(\"td\")[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "396\n"
     ]
    }
   ],
   "source": [
    "# Find the Total Yards for the Seahawks\n",
    "# print(parser.find_all(id = \"total-yards\")[0].find_all(\"td\")[1].text)\n",
    "# print(parser.select(\"#total-yards\")[0].select(\"td\")[1].text)\n",
    "print(parser.find_all(id = \"total-yards\")[0].select(\"td\")[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've covered the basics of HTML and how to select elements, which are key foundational blocks.\n",
    "\n",
    "We might be wondering why Web scraping is useful, given that in most of our examples, we could easily have found the answer by looking at the page. The real power of Web scraping lies in getting information from a large amount of pages very quickly.\n",
    "\n",
    "Let's say we wanted to find the total number of yards each NFL team gained in every single NFL game over an entire season. We could do this manually, but it would take days of boring drudgery. We could write a script to automate this in a couple of hours instead, and have a lot more fun doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
